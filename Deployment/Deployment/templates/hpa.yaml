apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{.Values.frontendHorizonzalPodautoscalerName}} 
  namespace: {{.Values.environment}}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{.Values.frontendDeploymentName}}
  minReplicas: {{.Values.frontendPodsReplicas}}
  maxReplicas: {{.Values.frontendPodsMaxreplicas}}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: {{.Values.frontendPodCpuUtilization}} 
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: {{.Values.frontendPodMemoryUtilization}}

# install metric server on the kind cluster check the metric-server.yaml file to see how
# kubectl get hpa   ------ to the targeted pod cpu and memory utilization
# load testing our cluster endpoint to see if it can will auto scale at 50% cpu and 30% ram utiliazation use the command below
# kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"  -------  http://php-apache;   cluster ip connected to the pods

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{.Values.backendHorizonzalpodautoscalerName}}
  namespace: {{.Values.environment}}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{.Values.backendDeploymentName}}
  minReplicas: {{.Values.backendPodsReplicas}}
  maxReplicas: {{.Values.backendPodsMaxreplicas}}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: {{.Values.backendPodCpuUtilization}}
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: {{.Values.backendPodMemoryUtilization}}